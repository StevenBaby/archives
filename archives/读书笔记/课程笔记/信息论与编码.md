# 信息论与编码

[annotation]: [id] (1f320295-eb64-4b4e-aced-db913bec8cc6)
[annotation]: [status] (public)
[annotation]: [create_time] (2021-09-09 13:25:38)
[annotation]: [category] (读书笔记)
[annotation]: [tags] (研究生课程|信息论|编码)
[annotation]: [comments] (true)
[annotation]: [url] (http://blog.ccyg.studio/article/1f320295-eb64-4b4e-aced-db913bec8cc6)

主讲教师：吕克伟 王丽萍

## 概述

熵 (Entropy) 的起源：热力学第二定律

- 克劳修斯表述：
    - 不可能将热从低温物体传至高温物体而不引起其它变化
    - 热量不能自发的从低温物体传向高温物体
- 开尔文-普朗克表述：
    - 不可能从单一热源吸取热量，并将这热量变为功，而不产生其他影响

- 克劳修斯：《热力推动说》

---

- 克劳德·香农 - 《通信的数学理论》
- 保密通信的通信理论
    - 保密系统模型

- fuzzy extractor

基于 Lattice 的信息传输

- SVP
- CVP
- SIVP

保密系统的密钥量越小，其中含有的关于明文的信息量就越大

密文与文明之间的互信息为零

存在完美的保密系统

-----

什么是信息

信息是使概率分布发生改变的东西

----

1928 哈特莱 《信息传输》 **信息是选择的自由度**

- 维纳：信息既不是物质，也不是能量，信息就是信息

----

39 * x * 259

- 信号
- 信息
- 消息

```
信源 --编码--> 信道 --解码--> 信宿
```

信息论是一门应用概率论

---

香农三大定理：

- 香农第一定理：可变长无失真信源编码定理
- 香农第二定理：有噪信道编码定理
- 香农第三定理：保失真度 TODO

确定概率模型

---

## 信源及其信息量

信源 $S$ 输出以符号形式出现的具体消息，消息随机的。

可以概率统计的形式来描述

信源面临的问题：

1. 定量描述问题：如何计算信源的信息量
2. 信源编码问题：如何有效的表示信源的输出或信源信息的载体形式

----

信源大致的分类：

- 时间与幅度：
    - 离散信源：信源发出的消息在时间和幅度上都是离散的
    - 连续信源：信源发出的消息在时间和幅度上都是连续的
- 依据各维随机变量的概率分布是否随着时间推移而变化：
    - 平稳信源：每维概率分布几乎相同
    - 非平稳信源
- 依据随机变量间的是否统计独立:
    - 有记忆信源
    - 无记忆信源

主要研究的对象：离散信源、平稳信源

- 无记忆的
    - 单符号
    - 扩展
- 有记忆：
    - 记忆长度有限
    - 记忆长度无线

----

### 单符号离散信源

- 每次信源只发出一个符号，代表一个消息；
- 能够输出的消息是 **有限** 或 **可数** 的

可看成是一个随机事件，可抽象成 一维随机变量

--- 

信源 $S$

数学模型 $S = \begin{pmatrix} X \\ P(X) \end{pmatrix}$ 是一维随机变量分布律 

$0 \leqslant P(x_i) \leqslant 1$

$\displaystyle \sum_{i=1}^n P(x_i) = 1$

其中：

- $X$ 表示信源输出消息的全体
- $x_i$ 表示某一特定消息
- $P(x_i)$ 表示 $x_i$ 出现的概率
- $n$ 表示 $S$ 输出消息的个数

信源每次发送一个符号 --> 单符号信源

信源发出的符号是随机的，因此使用随机变量 $X$ 来表示 $S$

----

例子：假定一根电线上串联着 8 个灯泡 $\{x_1, x_2, \cdots, x_8\}$，每个灯泡损坏的概率是 $\displaystyle P(x_i) = {1 \over 8}$，如果有且仅有一个灯泡坏了，但不知道是哪个，试用万用表测量电路，获取足够的信息来确定损坏的灯泡 $x_i$？(要求测量次数最少)

分析：每个灯泡等概率的发生，$P(x_i) = {1 \over 8}$，对应的不确定性是 $P(x_i)$ 的负对数，记为 $I(P(x_i)) = -\log_2 P(x_i)$

$$S(x, P(x)) = \begin{pmatrix}
x_1, x_2, \cdots, x_8 \\\displaystyle
{1 \over 8}, {1 \over 8}, \cdots, {1 \over 8} \\
\end{pmatrix}$$

解：类似二分查找

- 没测量时 $P(x_i) = {1 \over 8}, I(P(x_i)) = 3$
- 第一次测量 $P(x_i) = {1 \over 4}, I(P(x_i)) = 2$
- 第二次测量 $P(x_i) = {1 \over 2}, I(P(x_i)) = 1$
- 第三次测量 $P(x_i) = 1, I(P(x_i)) = 0$

也就是说，我们至少需要 3 比特的信息可确定具体的灯泡。

--- 

收到某个消息 $m$ 获得信息量记为 $I(m)$ = 不确定性减少的量，也就是收到 $m$ 之前关于 $m$ 事件发生的不确定性 - 收到 $m$ 之后关于 $m$ 事件发生的不确定性；

----

定义：一个随机事件发生某一结果后，所带来的信息量，称为该事件的 **自信息量**，简称 **自信息**；若随机事件 $x$ 发生的概率为 $P(x)$，则定义其自信息量为:

$$I(x) = - \log_2 P(x)$$

也就是 $x$ 事件发生前，不确定性的大小，$x$ 事件发生后，事件 $x$ 含有或提供的信息量。

## 参考资料

- [A Mathematical Theory of Communication C.E.Shannon 1963](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf)
- 信息论 本质 多样性 统一

