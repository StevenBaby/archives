# 高级人工智能

[annotation]: [id] (f59b6767-f0b4-4960-9fc8-37195acfbf64)
[annotation]: [status] (public)
[annotation]: [create_time] (2021-12-26 13:13:31)
[annotation]: [category] (计算机科学)
[annotation]: [tags] (人工智能|机器学习|强化学习|神经网络|数理逻辑)
[annotation]: [comments] (true)
[annotation]: [url] (http://blog.ccyg.studio/article/f59b6767-f0b4-4960-9fc8-37195acfbf64)

## 人工智能概述

> 智能：个体适应环境并能在不同环境中实现其目标的能力

概念性定义：

- 机器智能：使机器具备计算和判别的行为能力
- 类脑智能：仿生智能，让机器像人或生物一样思考
- 群体智能：社会智能的机器重现与利用、涌现智能

### 人工智能的起源

- 萌芽期：
    - 机械自动化
    - 逻辑推理
- 孕育期（文艺复兴以来）：
    - 理性主义
    - 数理逻辑学课
    - 计算思维：巴贝奇：差分机，图灵机
- 形成期(1956-1961)：
    - 1956 年，首次人工智能研讨会
    - IBM 的西洋跳棋程序，文法体系、逻辑推理机
- 发展期 (60 年代)：
    - 研究领域拓展
    - 1969 年，第一届国际人工智能联合会议 (IJCAI)
    - 1970 年，《人工智能》国际杂志创刊
- 寒冬期 (60s-70s)：
    - 1966 年，美国政府取消了机器翻译项目的所有投资
    - 英国政府取消了几乎所有人工智能研究投入
    - 神经网络的研究经费缩减到几乎没有
- 艰难前行 (70s)：
    - 弱方法：构建搜索机制，试图找出完全解，下棋：搜索解空间
    - 强方法：构建领域知识库 --> 专家系统
- 走向工业 (80s)：
    - 1982 年，第一个商用专家系统RI
    - 1981 年，日本启动“第五代计算机”计划，运行 prolog 语言的智能计算机
    - 美国、英国恢复对人工智能的投入
- 今天：
    - 大数据、计算能力提升、网络泛在化
    - 神经网络复兴：多层感知机，反向传播，隐马尔可夫模型(语音识别)，贝叶斯网络
    - 专家系统逐渐成熟，知识发现、数据挖掘兴起

### 图灵测试

### 达特茅斯会议

首次提出 **人工智能** 一词

### 人工智能三大学派

- 符号主义：逻辑学派，认为 **人的认知基元是符号，认知过程即符号操作过程**
    - 逻辑
    - 专家系统
    - 知识库
- 联接主义：仿生学派或生理学派，认为 **人的思维基元是神经元**
    - 人工神经网络
    - 认知科学
    - 类脑计算
- 行为主义：进化主义或控制论学派，认为 **智能取决于感知和行动**
    - 主张 **利用机器对环境作用后的相应或反馈为原型** 来实现智能
    - 控制论(维纳)
    - 多智能体
    - 强化学习

### 人工智能研究的课题

三大层次

- 基础理论：数学、思维科学、认知科学等
- 原理技术：启发式搜索、演化计算
- 工程应用：模式识别、计算机视觉、自然语言处理、问答系统

四大问题：

- 知识科学
- 问题求解
- 机器学习
- 系统构成

> 许多尖端的人工智能由于应用广泛，已经不再被称为人工智能。因为，人们一旦觉得某些东西非常有用并广泛使用，就不再称之为人工智能了。 —— 尼克·博斯特罗姆

## 搜索问题

搜索问题构成：

- 状态空间
- 后继函数
- 初始状态和目标测试

> **解** 是一个行为序列，将初始状态转换成目标状态

例子：野人过河问题

有三个传教士(Missionary) 和三个野人(Cannibal) 要过河，只有一条能装下两个人的船(Boat)，在河的任何一方或者船上，如果野人的人数大于传教士的人数，那么传教士就会有危险，你能不能找出一种或多种安全的渡河方法呢？

- 状态空间：$\{(M, C, B)\}$
- 后继函数：$\{P01, P10, P02, P20, P11, Q01, Q10, Q02, Q20, Q11\}$
- 初始状态：$(3, 3, 1)$
- 目标状态：$(0, 0, 0)$

其中后继函数表示 $Pmc$ 表示从左岸滑向右岸，$Qmc$ 表示从右岸滑向左岸。

状态空间图：

![](./images/mc_space.drawio.svg)

该问题的解：最短路径有 4 条，由 11 次操作构成

- (P11、Q10、P02、Q01、P20、Q11、P20、Q01、P02、Q01、P02)
- (P11、Q10、P02、Q01、P20、Q11、P20、Q01、P02、Q10、P11)
- (P02、Q01、P02、Q01、P20、Q11、P20、Q01、P02、Q01、P02)
- (P02、Q01、P02、Q01、P20、Q11、P20、Q01、P02、Q10、P11)

### 无信息搜索

**状态空间图和搜索树**

- 状态空间图中，每种状态只出现一次
- 扩展出潜在行动
- 维护所考虑行动的边缘结点
- 试图扩展尽可能少的树结点

**搜索算法特性**：

- 完备性：当问题有解时，保证能找到可行解
- 最优性：当问题有解时，保证能找到最优解
- 时间复杂度
- 空间复杂度

**深度优先搜索**

策略：利用栈处理边缘结点

- 时间复杂度：$O(b^m)$，其中 $b$ 为每次扩展的结点数，$m$ 为树的高度
- 空间复杂度：$O(bm)$
- 完备性：树高 $m$ 可能无穷大，除非我们防止循环搜索
- 最优性：不具备，找到的是最左侧的解，而不关心深度和代价

**广度优先搜索**

策略：利用队列处理边缘节点

- 时间复杂度：$O(b^d)$，其中 $b$ 为每次扩展的结点数，$d$ 为找到解的高度
- 空间复杂度：$O(b^d)$
- 完备性：如果解存在，那么 $d$ 必须是有限的，所以具备完备性
- 最优性：如果所有搜索代价都是相等的，那么是可以找到最优解的

**代价一致搜索**

策略：优先扩展代价最低的结点，数据结构优先队列

- 时间复杂度：$O(b^{C^* / \varepsilon})$，其中 $b$ 为每次扩展的结点数，$C^*$ 为找到解的代价，$\varepsilon$ 为最少的弧代价
- 空间复杂度：$O(b^{C^* / \varepsilon})$
- 完备性：具备
- 最优性：具备
- 缺点：在每一个方向上进行搜索，没有关于目标的信息。

### 启发式搜索

启发策略：

- 估计一个当前状态到目标距离的函数
- 问题给算法额外的信息，为特定的搜索问题设计特定的算法

启发函数：

- 通常，可采纳的启发函数是 **松弛问题** 的解的代价（耗散）

贪婪搜索：

- 策略：扩展离目标最近的结点
- 只是用启发函数 $f(n) = h(n)$ 来评价结点
- 通常情况：很快到达目标
- 最坏情况：类似于 DFS

$A^*$ 搜索：

- 策略：结合代价一致搜索和贪婪搜索
- 代价一致，为后向代价 $g(n)$
- 贪婪，为前向代价 $h(n)$
- 启发函数 $f(n) = g(n) + h(n)$
- 只有目标出队列时才停止

启发函数 $h$ 时可采纳的，那么必须满足：

$$0 \leqslant h(n) \leqslant h^*(n)$$

其中 $h^*$ 时到最近目标的真实代价，而 $h$ 时估计代价，想到启发函数 $h$ 时 $A^*$ 算法的重点。

$A^*$ 树搜索的最优性的证明

最优性：设 $A$ 是最优目标结点，$B$ 是次优目标结点，$h$ 是可采纳的代价函数，那么 $A$ 在 $B$ 之前离开边缘集合。

假设 $B$ 在边缘集合上，$A$ 的某个祖先结点 $A_p$ 也在边缘集合上，那么有 $f(A_p) \leqslant f(A)$，

由于 $A$ 是最优解，而 $B$ 是次优解，所以有 $f(A_p) \leqslant f(A) < f(B)$；

归纳地可得，$A$ 的所有祖先结点在 $B$ 之前扩展，$\Rightarrow$ $A$ 在 $B$ 之前扩展；

故 $A^*$ 是最优的；

### 局部搜索

局部搜索：改进单一选项直到不能再改善为止，没有边缘结合

新的后继函数：局部改变

通常更快，内存使用更有效，但不完备，次优，对于很难找到最优解的问题，通常次优解也是不错的选择。

爬山法：

- 可在任意位置开始
- 重复：移动到最好的相邻状态
- 如果没有比当前更好的相邻状态，则结束

模拟退火算法：

- 避免局部极大值（允许向山下移动）
- 静态分布 $p(x) \propto e^{E(x) \over kT}$
- 如果温度下降的足够慢，将收敛到最优解

遗传算法：

- 基于 **适应度函数**，再每步中保留 $N$ 个最好状态
- 配对杂交操作
- 产生可选的变异

## 神经网络和深度学习

- 联接主义学派或生理学派
    - 认为人的思维基元是神经元，而不是符号处理过程
    - 认为人脑不同于电脑
- 核心：智能的本质是联接机制
- 原理：神经网络及神经网络间的联接机制和学习算法

所谓人工神经网络是基于模仿生物大脑的结构和功能而构成的一种信息处理系统。

### 生物学启示

![](./images/neural_network.jpg)

- 神经元的组成：
    - 细胞体
    - 轴突
    - 树突
    - 突触
- 神经元之间通过突触两两相连，信息的传递通过动作电位发生在突触；
- 突触记录了神经元间联系的强弱；
- 只有达到一定的兴奋程度，神经元才向外输出信息；

TODO...

---

M-P 模型 <sup>[[ref]](#mp)</sup>：

$y = f(\xi) = f(g(x))$

其中：

- $f$ 为激活函数 (Activation Function)
- $g$ 为组合函数 (Combination Function)

加权和

$\displaystyle \xi = g(x) = \sum_{i = 1}^n w_ix_i - \theta$

其中：

- $w_i$ 为权重
- $\theta$ 为偏置，一般用 $b$ (bias) 表示

----

激活函数：

Sigmoid 函数 

$$\text{sigmoid}(\xi) = {1 \over 1 + e^{-\alpha \xi}}$$

ReLU 函数

$$\text{relu}(\xi) = \max\{0, \xi \}$$

多个神经元按照特定的网络结构联接在一起，就构成了一个人工神经网络，神经网络的目标就是将输入转换成有意义的输出。

### 感知机

> 感知机收敛定理：若训练集是线性可分的，则感知机模型收敛；

证明：

记 $\hat{w} = [w^T b]^T$, $\hat{x} = [x^T 1]^T$，则分离的超平面为 $\hat{w}^T \hat{x} = 0$

如果数据集线性可分，那么存在 $\hat{w}^*(\parallel \hat{w}^* \parallel = 1), \gamma > 0$，使得 $y_t \hat{w}^* x_t \geqslant \gamma$

令最终的分离超平面参数为 $\hat{w}^*$ 且其范数为 $1$

$$\begin{aligned}
\hat{w}_k \hat{w}^* =& (\hat{w}_{k - 1} + \hat{x}_t y_t) \hat{w}^* \geqslant \hat{w}_{k - 1} \hat{w}^* + \gamma \geqslant \cdots \geqslant k \gamma \\
\parallel \hat{w}_k \parallel^2 =& \parallel \hat{w}_{k - 1} + \hat{x}_t y_t \parallel^2 = \parallel \hat{w}_{k - 1} \parallel^2 + 2 \hat{w}_{k-1}^T \hat{x}_ty_t + \parallel \hat{x}_t \parallel^2 \\
\leqslant & \parallel \hat{w}_{k - 1} \parallel^2 + \parallel \hat{x}_t \parallel^2 \\
\leqslant & \parallel \hat{w}_{k - 1} \parallel^2 + R^2 \\
\leqslant & \cdots \\
\leqslant & kR^2 \\
\end{aligned}$$

于是 $k\gamma \leqslant \hat{w}_k \cdot \hat{w}^* \leqslant \parallel \hat{w}_k \parallel \cdot \parallel \hat{w}^* \parallel \leqslant \sqrt{k}R$ 

故 $\displaystyle k \leqslant {R^2 \over \gamma^2}$

解读：给定训练集 $D = \{(x^{(n)}, y^{(n)})\}_{n = 1}^N$，令 $R$ 是训练集中最大的特征向量的模，即：


$$R = \max_n \parallel x^{(n)} \parallel$$

如果训练集 $D$ 线性可分，两类感知机的参数学习算法的权重更新次数不会超过 $\displaystyle {R^2 \over \gamma^2}$

---

反向传播算法

均方误差函数 

梯度下降

梯度消失

### 深度学习

- 自动编码器
- Hopfield 网络
- 玻尔兹曼机

---

受限玻尔兹曼机 Restricted Boltzmann Machine (RBM)

----

深度信念网络 Deep Belief Networks(DBN)

深度信念网络（DBN）是一种多层网络，每两层网络受限于波兹曼机（RBM）。可以假设 DBN 是由众多 RBM 堆积而成的。

在 DBN 中，每个隐含层可以理解为是输入特征的抽象表示。它执行分类任务，其输出层是不同的。在 DBN 中可执行两个任务，无监督预训练和监督微调。

无监督预训练：在 RBM 中训练以重建输入。每一层接收来自前一层的输入。

监督微调：在这个过程中，利用标签和反向传播算法的梯度下降进行训练。

---

Deep Boltzmann Machine(DBM)

## 循环神经网络

循环神经网络 (Recurrent Neutral Networks, RNN)，学习序列数据，常常需要转换输入序列到不同领域的输出序列

GRU 单元 (Gated Recurrent Unit)

LSTM

BRNN

Deep RNN

## 卷积神经网络

卷积神经网络是一种特殊的深层神经网络模型

- 它的神经元间的连接是非全连接的
- 同一层中某些神经元之间的连接的权重是共享的

局部感受野：

- 图像的空间联系也是局部的像素联系较为紧密，而距离较远的像素相关性则较弱
- 减少了需要训练的权值数目


参数共享

卷积

边缘填充

步长

池化

Dropout

### 卷积神经网络实例

- ImageNet
- VGG Net
- ResNets
- Inception Net
- GoogleLeNet

## 生成对抗神经网络

- 生成器
- 判别器
- 纳什均衡

## 图神经网络

## 命题逻辑的语义推论

- 知识库(Knowledge Base, KB)：形式语言句子的集合；

1. 声明式的构建一个系统，将想要知道的都告诉它；
2. 然后问它问题，答案将会从知识库中得到；
3. 使得推理变成一个机械的过程；

- **逻辑**：表示信息以便得出结论的形式语言
- **语法**：定义语言中的句子
- **语义**：定义句子的含义；

----

### 逻辑研究的内容

- 语义：蕴含 entailment，逻辑推导
- 语法：演绎 inference，形式推演

![](./images/logic_01.drawio.svg)

- 可靠性：若句子 $S$ 可以用逻辑规则推演得到，那么 $S$ 为真
- 完备性：若句子 $S$ 为真，那么 $S$ 一定可以用逻辑规则推演得到
- 蕴含：$KB\vDash \alpha$，可以理解为 $KB$ 是 $\alpha$ 的充分条件，也可以理解为 $KB$ 是 $\alpha$ 的子集；

### 命题逻辑

- 命题：一个可以判断真假的句子
- 原子命题：不包含其他命题作为其组成部分的命题
- 文字：原子命题或者原子命题的否定

---

**命题逻辑的语法**

设 $S, S_1, S_2$ 为句子，那么

- 否定：$\neg S$ 为非 $S$
- 合取：$S_1 \wedge S_2$ 为 $S_1$ 或 $S_2$
- 析取：$S_1 \vee S_2$ 为 $S_1$ 与 $S_2$
- 蕴涵：$S_1 \Rightarrow S_2$，为如果 $S_1$，则 $S_2$
- 等价：$S_1 \Leftrightarrow S_2$，为 $S_1$ 和 $S_2$ 等价

**语义逻辑等价**

$$\begin{aligned}
A \wedge B &\equiv B \wedge A \\
A \vee B &\equiv B \vee A \\
(A \wedge B) \wedge C &\equiv A \wedge (B \wedge C) \\
(A \vee B) \vee C &\equiv A \vee (B \vee C) \\
\neg (\neg A) &\equiv A \\
A \Rightarrow B &\equiv \neg B \Rightarrow \neg A \\
A \Rightarrow B &\equiv \neg A \vee B \\
A \Leftrightarrow B &\equiv (A \Rightarrow B) \wedge (B \Rightarrow A) \\
\neg(A \wedge B) &\equiv \neg A \vee \neg B \\
\neg(A \vee B) &\equiv \neg A \wedge \neg B \\
A \wedge (B \vee C) &\equiv (A \wedge B) \vee (A \wedge C) \\
A \vee (B \wedge C) &\equiv (A \vee B) \wedge (A \vee C) \\
\end{aligned}$$

-----

- 真假赋值：是以所有命题符号的集为定义域，以真假值的集 $\{1,0\}$ 为值域的映射；
- 可满足性：$\Sigma$ 是可满足的，当且仅当有真假赋值 $v$ ，使得 $\Sigma^v = 1$，当 $\Sigma^v = 1$ 时，称 $v$ 满足 $\Sigma$；
- 重言式：$A$ 是重言式，当且仅当对于任意真假赋值 $v$ 都有 $A^v = 1$；
- 矛盾式：$A$ 是矛盾式，当且仅当对于任意真假赋值 $v$ 都有 $A^v = 0$；

## 命题逻辑的形式推演

### 形式推演的规则

----

合取范式：形如 $C_1 \wedge \cdots \wedge C_m$ 的式子，其中子句 $C_i$ 的形式为 $l_1 \vee \cdots \vee l_k$

**归结原理** <sup>[[ref]](#resolution)</sup>

$$l_1 \vee \cdots \vee l_k, \qquad m_1 \vee \cdots \vee m_n \over l_1 \vee \cdots \vee l_{i - 1} \vee l_{i + 1} \cdots  \vee l_k \vee m_1 \vee \cdots \vee m_{j - 1} \vee m_{j + 1} \vee \cdots \vee m_n$$

其中 $l_i$ 与 $m_j$ 是互补的文字，也就是说 $l_i \equiv \neg m_j$；

> 归结原理对命题逻辑是及 **可靠(sound)** 又 **完备(complete)** 的；

---

证明：若 $\Sigma \not\vdash \varnothing$, $\Sigma \vdash \alpha$ 当且仅当 $\{\Sigma, \neg \alpha \} \vdash \varnothing$，其中 $\vdash$ 仅使用归结原理获得新子句；

---

Modus Ponens 规则：

$$a_1, \cdots, a_n, \quad a_1, \cdots, a_n \Rightarrow b \over b$$

----

证明：Modus Ponens 规则是可靠的，即

$$a_1 \wedge \cdots \wedge a_n \wedge ( a_1 \wedge \cdots \wedge a_n \Rightarrow b) \vDash b$$

证明：

1. 构造如下真值赋值(指派 assignment) $m$，对任意文字 $a$，$a$ 赋值为 `true`，当且仅当 $a \in RC(KB)$ 

todo

---

## 一阶谓词逻辑

- 对象
- 关系
- 函数

----

- 常量
- 谓词
- 函数 
- 变量
- 连接词
- 等价
- 量词


## 模糊知识表达推理

## 知识表示学习

## 演化计算

## 群体智能

群体智能指的是 **无智能** 或者仅具有 **相对简单智能** 的 主体 通过 **合作涌现** 出更高智能行为的特性

单个复杂个体可以实现的功能，同样可以由大量简单的个体通过群体合作实现，后者的优势在于它更健壮、灵活和经济。

群体智能利用群体优势，在没有中心控制的条件下，寻找解决复杂问题的新思路。


- 集群智能：众多无智能的个体，通过相互之间的简单合作所表现出来的智能行为
- 博弈：具备一定智能的理性个体，按照某种机制行动，在群体层面体现出的智能
- 众包：设计合适的机制，激励个体参与，从而实现单个个体不具备的社会智能

集群智能是 **分布式**、**自组织** 的（自然/人造）系统表现出的一种群体智能

集群智能系统一般由一群简单的智能体构成，智能体按照简单的规则彼此进行局部交互，智能体也可以环境交互；

集群智能的特点：

- 分布式：无中心控制
- 随机性：非确定性
- 自适应：个体根据环境进行策略调整
- 正反馈：个体好的尝试会对个体产生正反馈
- 自发涌现：会在群体层面涌现出一种智能

### 蚁群优化算法

Ant Colony Optimization (ACO) <sup>[[ref]](#ant)</sup>：

- 一种解空间搜索方法
- 适用于在图上寻找最优路径

形式化：

- 每个蚂蚁对应一个计算智能体
- 蚂蚁依概率选择侯选位置进行移动
- 在经过的路径上留下 **信息素(Pheromone)**
- 信息素随时间挥发
- 信息素浓度大的路径在后续的选择中会以更高的概率被选取

-----

旅行商问题 (Traveling Salesman Problem, TSP)：

- $n$ 个城市的有向图 $G = (V, E)$
- 城市之间的距离表示为 $d_{ij}$，表示结点 $i$ 和 $j$ 之间的距离
- 目标函数 $\displaystyle f(w) = \sum_{l = 1}^n d_{i_l i_{l + 1}}$，$w = (i_1, i_2, \cdots, i_n)$，为旅行商问题的任意可行解，其中 $i_{n + 1} = i_1$

算法：

首先将 $m$ 只蚂蚁随机放置在 $n$ 个城市，位于城市 $i$ 的第 $k$ 只蚂蚁选择下一个城市 $j$ 的概率为：

$$p_{ij}^k(t) = \begin{cases}
{[\tau_{ij}(t)]^\alpha[\eta_{ij}(t)]^\beta \over \sum_{k \in \text{allowed}} [\tau_{ik}(t)]^\alpha [\eta_{ik}(t)]^\beta}, & j \in \text{allowed} \\
0, & \text{otherwise}
\end{cases} \quad (1)$$

其中：

- $\tau_{i, j}(t)$ 表示边 $(i, j)$ 上的信息素浓度；
- $\eta_{i, j}(t) = {1 \over d_{ij}}$，是根据距离定义的启发信息
- $\alpha, \beta$ 反映了信息素与启发信息的相对重要性。

当所有蚂蚁完成周游后，按一下公式进行信息素更新：

$$\begin{aligned}
\Delta \tau_{ij}^k &= f(x) = \begin{cases}
{Q \over L_k}, & (i, j) \in w_k \\
0, & \text{otherwise}
\end{cases}  \quad (2)\\
\tau_{ij} (t + 1) &= \rho \cdot \tau_{i j} (t) + \Delta \tau_{ij} \\
\Delta \tau_{ij} &= \sum_{k = 1}^m \Delta \tau_{ij}^k
\end{aligned}$$

其中：

- $Q$ 为常数
- $w_k$ 表示第 $k$ 只蚂蚁在本轮迭代中走过的路径
- $L_k$ 为路径长度
- $\rho$ 为小于 $1$ 的常数，反应信息素的挥发速度

TSP 问题蚁群算法流程：

```ruby
1. 初始化，随机防止蚂蚁
2. 迭代过程
k = 1
while k <= count do:
    for i = 1 to m do:
        for j = 1 to n - 1 do:
            根据式 (1) 采用轮盘赌方法在窗口外选择下一个城市 j;
            将 j 置入禁忌表，蚂蚁转移到 j;
        end for
    end for
    计算每只蚂蚁的路径长度;
    根据式(2)更新所有蚂蚁路径上的信息量;
    k += 1;
end while
3. 输出结果，结束算法;
```

- 蚁群大小：一般情况下，蚁群的蚂蚁个数不超过 TSP 图中结点的个数
- 终止条件：
    - 设定迭代轮数
    - 设定最优解连续保持不变的迭代轮数
- 思想：
    - 局部随机搜索 + 子增强
    - 鲁迅：世界上本无路，走的人多了便有了路；
- 缺点：
    - 收敛速度慢
    - 易于陷入局部最优
    - 对于解空间为连续的优化问题不适用
    - 图中有环可能会陷入环中，环中的信息素不断增强；

### 粒子群算法

粒子群优化算法是一种基于种群寻优的启发式搜索算法。在 1995 年由Kennedy 和 Eberhart 首先提出来的。

它的主要启发来源于对鸟群群体运动行为的研究。我们经常可以观察到鸟群表现出来的同步性，虽然每只鸟的运动行为都是互相独立的，但是在整个鸟群的飞行过程中却表现出了高度一致性的复杂行为，并且可以自适应的调整飞行的状态和轨迹。

鸟群具有这样的复杂飞行行为的原因，可能是因为每只鸟在飞行过程中都遵循了一定的行为规则，并能够掌握邻域内其它鸟的飞行信息。

粒子群优化算法借鉴了这样的思想，每个粒子代表待求解问题搜索解空间中的一个潜在解，它相当于一只鸟，“飞行信息”包括粒子当前的位置和速度两个状态量。

每个粒子都可以获得其邻域内其它个体的信息，对所经过的位置进行评价，并根据这些信息和位置速度更新规则，改变自身的两个状态量，在“飞行”过程中传递信息和互相学习，去更好地适应环境。

随着这一过程的不断进行，粒子群最终能够找到问题的近似最优解。

-----

PSO: Particle Swarm Optimization <sup>[[ref]](#particle)</sup>：

- 一种随机优化方法
- 通过粒子群在解空间中进行搜索，寻找最优解（适应度最大的解）

构成要素形式化：

- 粒子群：
    - 每个粒子对应求解问题的一个可行解
    - 粒子通过其位置和速度表示
    - 粒子 $i$ 在第 $n$ 轮的位置：$x_n^{(i)}$
    - 粒子 $i$ 在第 $n$ 轮的速度：$v_n^{(i)}$
- 记录：
    - $p_{best}^{(i)}$ 粒子 $i$ 的历史最好位置
    - $g_{best}$ 全局历史最好位置
- 计算适应度函数：$f(x)$

算法过程描述：

- 初始化:
    - 初始化粒子群：每个粒子的位置和速度，即 $x_n^{(i)}$ 和 $v_n^{(i)}$
    - $p_{best}^{(i)}$ 和 $g_{best}$
- 循环直至结束：
    - 计算每个粒子的适应度：$f(x_n^{(i)})$
    - 更新每个粒子历史最好适应度及其相应的位置
    - 更新当前全局最好适应度及其相应的位置
    - 以下列公式更新每个粒子的速度和位置

$$\begin{aligned}
v_{n + 1}^{(i)} &= v_n^{(i)} + c_1 \cdot r_1 \cdot \left( p_{best}^{(i)} - x_n^{(i)}\right) + c_2 \cdot r_2 \cdot \left( g_{best} - x_n^{(i)}\right)\\
x_{n + 1}^{(i)} &= x_n^{(i)} + v_{n + 1}^{(i)}
\end{aligned}$$

其中：

- $v_n^{(i)}$ 表示惯性，粒子会以原速度保持不变的倾向；
- $p_{best}^{(i)} - x_n^{(i)}$：记忆项，粒子回到历史最好位置的倾向；
- $g_{best} - x_n^{(i)}$：社会项，走向粒子群全局最好位置的倾向；
- $c_1, c_2$，为权重参数，一般取值为 $2$
- $r_1, r_2$，为 $[0, 1]$ 之间的随机数

算法终止条件：

- 迭代的轮数
- 最佳位置连续未更新的轮数
- 适应度函数的值达到预期要求

速度更新参数分析，又称加速度参数，用来控制粒子当前最优解位置 $p_{best}^{(i)}$ 和粒子全局最优解位置 $g_{best}$ 对飞行速度的影响；

- $c_1 > 0, c_2 = 0$：每个粒子执行局部搜索；
- $c_1 = 0, c_2 > 0$：算法转化为一个随机爬山法；
- $c_1 = c_2 > 0$：粒子逐渐移向 $\vec{p}_g$ 和 $\vec{p}_i$ 的加权均值；
- $c_1 < c_2$：算法比较适合于单峰优化问题；
- $c_1 > c_2$：算法比较适合于多峰优化问题；

和遗传算法相比：

- 遗传算法强调 **适者生存**，适应度低的个体在竞争中被淘汰；PSO 强调 **协同合作**，适应度低的个体通过学习适应度好的个体，向好的方向转变；
- 遗传算法中最好的个体通过产生更多的后代来传播基因；PSO 中的最好个体通过吸引其他个体向他靠拢来施加影响；
- 遗传算法的选择概率只与上一代群体相关，而与历史无关，群体的信息变化过程是一个马尔可夫链过程；而 PSO 的个体除了有位置和速度外，还有这过去的历史信息 $p_{best}, g_{best}$；

优点：

- 易于实现
- 可调参数较少
- 所需种群或微粒群规模较小；
- 计算效率高，收敛速度快；
- 适用于连续空间的求解；

缺点：和其他演化计算算法类似，不具有最优性；


## 强化学习

## 博弈

## 统计中的因果推断

### 为什么学习因果推断？

克服传统方法的不足

- 相关不意味着因果
- 缺少从数据中解读因果关系的有效数学语言或工具
- 统计无法回答反事实问题

### 辛普森悖论

**总体数据** 上得出的统计结论和 **分组数据** 上的统计结论相反

## 参考文献

1. <t id='mp'/> McClloch and Pitts, A logical calculus of the ideas immanent in nervous activity, 1943
2. <t id='infer'/>Judea Pearl, Madelyn Glymour, Nicholas P. Jewell Causal Inference in Statistics, Wiley 2016
3. <t id='resolution'/> J. A. Robinson. A machine-oriented logic based on the resolution principle.  Journal of the ACM, 1965, 12(1):23-41
4. <t id='ant'/>  A. Colorni, M. Dorigo et V. Maniezzo, Distributed Optimization by Ant Colonies, actes de la première conférence européenne sur la vie artificielle, Paris, France, Elsevier Publishing, 134-142, 1991.
5. <t id='particle'/> James Kennedy and Russell Eberhart. Particle swarm optimization. Proceedings of the IEEE International Conference on Neural Networks, pp. 1942–1948, Piscataway, NJ, 1995. 


