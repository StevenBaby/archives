# 高级人工智能

[annotation]: [id] (f59b6767-f0b4-4960-9fc8-37195acfbf64)
[annotation]: [status] (public)
[annotation]: [create_time] (2021-12-26 13:13:31)
[annotation]: [category] (计算机科学)
[annotation]: [tags] (人工智能|机器学习|强化学习|神经网络|数理逻辑)
[annotation]: [comments] (true)
[annotation]: [url] (http://blog.ccyg.studio/article/f59b6767-f0b4-4960-9fc8-37195acfbf64)

## 人工智能概述

> 智能：个体适应环境并能在不同环境中实现其目标的能力

概念性定义：

- 机器智能：使机器具备计算和判别的行为能力
- 类脑智能：仿生智能，让机器像人或生物一样思考
- 群体智能：社会智能的机器重现与利用、涌现智能

### 人工智能的起源

- 萌芽期：
    - 机械自动化
    - 逻辑推理
- 孕育期（文艺复兴以来）：
    - 理性主义
    - 数理逻辑学课
    - 计算思维：巴贝奇：差分机，图灵机
- 形成期(1956-1961)：
    - 1956 年，首次人工智能研讨会
    - IBM 的西洋跳棋程序，文法体系、逻辑推理机
- 发展期 (60 年代)：
    - 研究领域拓展
    - 1969 年，第一届国际人工智能联合会议 (IJCAI)
    - 1970 年，《人工智能》国际杂志创刊
- 寒冬期 (60s-70s)：
    - 1966 年，美国政府取消了机器翻译项目的所有投资
    - 英国政府取消了几乎所有人工智能研究投入
    - 神经网络的研究经费缩减到几乎没有
- 艰难前行 (70s)：
    - 弱方法：构建搜索机制，试图找出完全解，下棋：搜索解空间
    - 强方法：构建领域知识库 --> 专家系统
- 走向工业 (80s)：
    - 1982 年，第一个商用专家系统RI
    - 1981 年，日本启动“第五代计算机”计划，运行 prolog 语言的智能计算机
    - 美国、英国恢复对人工智能的投入
- 今天：
    - 大数据、计算能力提升、网络泛在化
    - 神经网络复兴：多层感知机，反向传播，隐马尔可夫模型(语音识别)，贝叶斯网络
    - 专家系统逐渐成熟，知识发现、数据挖掘兴起

### 图灵测试

### 达特茅斯会议

首次提出 **人工智能** 一词

### 人工智能三大学派

- 符号主义：逻辑学派，认为 **人的认知基元是符号，认知过程即符号操作过程**
    - 逻辑
    - 专家系统
    - 知识库
- 联接主义：仿生学派或生理学派，认为 **人的思维基元是神经元**
    - 人工神经网络
    - 认知科学
    - 类脑计算
- 行为主义：进化主义或控制论学派，认为 **智能取决于感知和行动**
    - 主张 **利用机器对环境作用后的相应或反馈为原型** 来实现智能
    - 控制论(维纳)
    - 多智能体
    - 强化学习

### 人工智能研究的课题

三大层次

- 基础理论：数学、思维科学、认知科学等
- 原理技术：启发式搜索、演化计算
- 工程应用：模式识别、计算机视觉、自然语言处理、问答系统

四大问题：

- 知识科学
- 问题求解
- 机器学习
- 系统构成

> 许多尖端的人工智能由于应用广泛，已经不再被称为人工智能。因为，人们一旦觉得某些东西非常有用并广泛使用，就不再称之为人工智能了。 —— 尼克·博斯特罗姆

## 搜索问题

搜索问题构成：

- 状态空间
- 后继函数
- 初始状态和目标测试

> **解** 是一个行为序列，将初始状态转换成目标状态

例子：野人过河问题

有三个传教士(Missionary) 和三个野人(Cannibal) 要过河，只有一条能装下两个人的船(Boat)，在河的任何一方或者船上，如果野人的人数大于传教士的人数，那么传教士就会有危险，你能不能找出一种或多种安全的渡河方法呢？

- 状态空间：$\{(M, C, B)\}$
- 后继函数：$\{P01, P10, P02, P20, P11, Q01, Q10, Q02, Q20, Q11\}$
- 初始状态：$(3, 3, 1)$
- 目标状态：$(0, 0, 0)$

其中后继函数表示 $Pmc$ 表示从左岸滑向右岸，$Qmc$ 表示从右岸滑向左岸。


该问题的解：最短路径有 4 条，由 11 次操作构成

- (P11、Q10、P02、Q01、P20、Q11、P20、Q01、P02、Q01、P02)
- (P11、Q10、P02、Q01、P20、Q11、P20、Q01、P02、Q10、P11)
- (P02、Q01、P02、Q01、P20、Q11、P20、Q01、P02、Q01、P02)
- (P02、Q01、P02、Q01、P20、Q11、P20、Q01、P02、Q10、P11)

### 无信息搜索

**状态空间图和搜索树**

- 状态空间图中，每种状态只出现一次
- 扩展出潜在行动
- 维护所考虑行动的边缘结点
- 试图扩展尽可能少的树结点

**搜索算法特性**：

- 完备性：当问题有解时，保证能找到可行解
- 最优性：当问题有解时，保证能找到最优解
- 时间复杂度
- 空间复杂度

**深度优先搜索**

策略：利用栈处理边缘结点

- 时间复杂度：$O(b^m)$，其中 $b$ 为每次扩展的结点数，$m$ 为树的高度
- 空间复杂度：$O(bm)$
- 完备性：树高 $m$ 可能无穷大，除非我们防止循环搜索
- 最优性：不具备，找到的是最左侧的解，而不关心深度和代价

**广度优先搜索**

策略：利用队列处理边缘节点

- 时间复杂度：$O(b^d)$，其中 $b$ 为每次扩展的结点数，$d$ 为找到解的高度
- 空间复杂度：$O(b^d)$
- 完备性：如果解存在，那么 $d$ 必须是有限的，所以具备完备性
- 最优性：如果所有搜索代价都是相等的，那么是可以找到最优解的

**代价一致搜索**

策略：优先扩展代价最低的结点，数据结构优先队列

- 时间复杂度：$O(b^{C^* / \varepsilon})$，其中 $b$ 为每次扩展的结点数，$C^*$ 为找到解的代价，$\varepsilon$ 为最少的弧代价
- 空间复杂度：$O(b^{C^* / \varepsilon})$
- 完备性：具备
- 最优性：具备
- 缺点：在每一个方向上进行搜索，没有关于目标的信息。

### 启发式搜索

启发策略：

- 估计一个当前状态到目标距离的函数
- 问题给算法额外的信息，为特定的搜索问题设计特定的算法

启发函数：

- 通常，可采纳的启发函数是 **松弛问题** 的解的代价（耗散）

贪婪搜索：

- 策略：扩展离目标最近的结点
- 只是用启发函数 $f(n) = h(n)$ 来评价结点
- 通常情况：很快到达目标
- 最坏情况：类似于 DFS

$A^*$ 搜索：

- 策略：结合代价一致搜索和贪婪搜索
- 代价一致，为后向代价 $g(n)$
- 贪婪，为前向代价 $h(n)$
- 启发函数 $f(n) = g(n) + h(n)$
- 只有目标出队列时才停止

启发函数 $h$ 时可采纳的，那么必须满足：

$$0 \leqslant h(n) \leqslant h^*(n)$$

其中 $h^*$ 时到最近目标的真实代价，而 $h$ 时估计代价，想到启发函数 $h$ 时 $A^*$ 算法的重点。

$A^*$ 树搜索的最优性的证明

最优性：设 $A$ 是最优目标结点，$B$ 是次优目标结点，$h$ 是可采纳的代价函数，那么 $A$ 在 $B$ 之前离开边缘集合。

假设 $B$ 在边缘集合上，$A$ 的某个祖先结点 $A_p$ 也在边缘集合上，那么有 $f(A_p) \leqslant f(A)$，

由于 $A$ 是最优解，而 $B$ 是次优解，所以有 $f(A_p) \leqslant f(A) < f(B)$；

归纳地可得，$A$ 的所有祖先结点在 $B$ 之前扩展，$\Rightarrow$ $A$ 在 $B$ 之前扩展；

故 $A^*$ 是最优的；

### 局部搜索

局部搜索：改进单一选项直到不能再改善为止，没有边缘结合

新的后继函数：局部改变

通常更快，内存使用更有效，但不完备，次优，对于很难找到最优解的问题，通常次优解也是不错的选择。

爬山法：

- 可在任意位置开始
- 重复：移动到最好的相邻状态
- 如果没有比当前更好的相邻状态，则结束

模拟退火算法：

- 避免局部极大值（允许向山下移动）
- 静态分布 $p(x) \propto e^{E(x) \over kT}$
- 如果温度下降的足够慢，将收敛到最优解

遗传算法：

- 基于 **适应度函数**，再每步中保留 $N$ 个最好状态
- 配对杂交操作
- 产生可选的变异

## 神经网络和深度学习

## 循环神经网络

## 卷积神经网络

## 生成对抗神经网络

## 图神经网络

## 命题逻辑的语义推论

## 命题逻辑的形式推演

## 谓词逻辑

## 模糊知识表达推理

## 知识表示学习

## 演化计算

## 强化学习

## 博弈

## 统计中的因果推断 <sup>[[ref]](#infer)</sup>

### 为什么学习因果推断？

克服传统方法的不足

- 相关不意味着因果
- 缺少从数据中解读因果关系的有效数学语言或工具
- 统计无法回答反事实问题

### 辛普森悖论

**总体数据** 上得出的统计结论和 **分组数据** 上的统计结论相反

## 参考文献

1. <t id='infer'/>Judea Pearl, Madelyn Glymour, Nicholas P. Jewell Causal Inference in Statistics, Wiley 2016
